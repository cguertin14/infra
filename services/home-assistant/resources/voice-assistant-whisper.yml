apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: whisper-storage
  labels:
    app.kubernetes.io/name: whisper
spec:
  storageClassName: nfs-client
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
---
apiVersion: v1
kind: Service
metadata:
  name: whisper
  labels:
    app.kubernetes.io/name: whisper
spec:
  selector:
    app.kubernetes.io/name: whisper
  type: NodePort
  ports:
  - name: whisper
    protocol: TCP
    port: 10300
    targetPort: 10300
    nodePort: 30300
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: whisper
  labels: 
    app.kubernetes.io/name: whisper
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: whisper
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: whisper
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/hostname
                  operator: In
                  values:
                    - nvidiaserver
      containers:
      # TODO: Add Nvidia GPU mount here.
      # See https://hub.docker.com/r/linuxserver/faster-whisper for details.
      # Also see https://egemengulpinar.medium.com/running-whisper-large-v3-on-docker-with-gpu-support-e8a5b5daabf9.
      - name: whisper
        image: lscr.io/linuxserver/faster-whisper
        envFrom:
        - configMapRef:
            name: whisper-config
        resources:
          limits:
            nvidia.com/gpu: 1 # Request 1 GPU
        ports:
        - containerPort: 10300
          name: whisper
        volumeMounts:
        - name: whisper-storage
          mountPath: /config
      volumes:
      - name: whisper-storage
        persistentVolumeClaim:
          claimName: whisper-storage
      restartPolicy: Always